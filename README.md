# adobe-round-1b
# PDF Q&A Pipeline (Round 1B)

A generic, offline, CPU-only system that ingests PDFs, extracts structured sections, and ranks them semantically against any â€œpersona + job-to-be-doneâ€ query. Built atop your robust 1A parser, this solution uses lightweight embeddings, dynamic keyword expansion, and precision-driven filters to surface the most relevant passages.

---

## ğŸš€ Features

- **1A Parsing**: Merges fragmented text, detects headers by font size/weight, slices into coherent sections.  
- **Dynamic Query Expansion**: KeyBERT + semantic search against a corpus vocabulary for domain-specific jargon.  
- **IDF-Weighted Embedding**: Blends fullâ€query, rare-phrase and â€œlastâ€wordâ€ embeddings for laser-focused relevance.  
- **Chunk-Level Ranking**: Cosineâ€similarity on paragraph chunks, aggregated per section.  
- **Precision Filters**: Similarity threshold, n-gram overlap, and post-rank summary checks.  
- **JSON Output**: Metadata, top N sections, importance ranks, and concise summaries.

---

## ğŸ“¦ Requirements

- Python 3.10+  
- PyMuPDF (`fitz`)  
- `sentence-transformers`  
- `keybert`  
- `scikit-learn`  
- `summa` (TextRank)  
- `numpy`

Install all dependencies with:

bash
pip install -r requirements.txt
`

---

## ğŸ”§ Configuration

Edit the top of `app.py`:

python
- MODEL_NAME          = 'sentence-transformers/all-MiniLM-L6-v2'
- TOP_N               = 10
- SIM_THRESHOLD_RATIO = 0.6    # keep sections â‰¥60% of top score
- NGRAM_N             = 3      # bigrams for phrase filtering
- ALPHA               = 0.3    # last-word boost weight
- BETA                = 0.6    # IDF-weighted keyphrase blend weight


Adjust these to trade off precision vs. recall.

---

## ğŸƒ Usage

1. **Place** your PDFs under `PDFs/`.

2. **Set** `PERSONA` and `JOB` in `main.py` (or notebook).

3. **Run**:

   bash
   python main.py
   

4. **Result** is written to `app/output/challenge1b_output.json`.

---

## âš™ Advanced Tuning

* **Threshold** (`SIM_THRESHOLD_RATIO`): higher â†’ more precise, less recall.
* **n-gram size** (`NGRAM_N`): lower â†’ catch shorter phrase fragments.
* **Alpha/Beta**: increase **Î²** to emphasize rare keyphrases; increase **Î±** to stress the final term of your JBTD.

Iterate to hit 80â€“90% precision while preserving recall.

---

## ğŸ—‚ Project Structure


project/
â”œâ”€â”€ pdf_parser.py    # 1A parsing logic
â”œâ”€â”€ app.py          # 1B pipeline
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---
